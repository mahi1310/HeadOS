{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d00122b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "from imutils import face_utils\n",
    "import utils\n",
    "import numpy as np\n",
    "import pyautogui as pyag\n",
    "import dlib\n",
    "import cv2\n",
    "from math import dist\n",
    "from scipy.spatial import distance as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d0aec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOUTH_AR_THRESH = 0.9\n",
    "MOUTH_AR_CONSECUTIVE_FRAMES = 15\n",
    "EYE_AR_THRESH = 0.20\n",
    "EYE_AR_CONSECUTIVE_FRAMES = 15\n",
    "WINK_AR_DIFF_THRESH = 0.005\n",
    "WINK_AR_CLOSE_THRESH = 0.5\n",
    "WINK_CONSECUTIVE_FRAMES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b6ea784",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOUTH_COUNTER = 0\n",
    "EYE_COUNTER = 0\n",
    "WINK_COUNTER = 0\n",
    "INPUT_MODE = False\n",
    "EYE_CLICK = False\n",
    "LEFT_WINK = False\n",
    "RIGHT_WINK = False\n",
    "SCROLL_MODE = False\n",
    "pyag.FAILSAFE = False\n",
    "ANCHOR_POINT = (0, 0)\n",
    "WHITE_COLOR = (255, 255, 255)\n",
    "YELLOW_COLOR = (0, 255, 255)\n",
    "RED_COLOR = (0, 0, 255)\n",
    "GREEN_COLOR = (0, 255, 0)\n",
    "BLUE_COLOR = (255, 0, 0)\n",
    "BLACK_COLOR = (0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d993fd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor\n",
    "shape_predictor = \"C:/Users/Mahitha/Downloads/shape_predictor_68_face_landmarks.dat/shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(shape_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2497b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the indexes of the facial landmarks for the left and\n",
    "# right eye, nose and mouth respectively\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "(nStart, nEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"nose\"]\n",
    "(mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95315b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video capture\n",
    "vid = cv2.VideoCapture(0)\n",
    "resolution_w = 1366\n",
    "resolution_h = 768\n",
    "cam_w = 640\n",
    "cam_h = 480\n",
    "unit_w = resolution_w / cam_w\n",
    "unit_h = resolution_h / cam_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6faa4773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns EAR given eye landmarks\n",
    "def eye_aspect_ratio(eye):\n",
    "    y1 = dist.euclidean(eye[1], eye[5])\n",
    "    y2 = dist.euclidean(eye[2], eye[4])\n",
    "    x1 = dist.euclidean(eye[0],eye[3])\n",
    "    ear = (y1+y2)/(2*x1)\n",
    "    cv2.putText(frame, str(ear), (300, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7,RED_COLOR, 2)\n",
    "    return ear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f3a2b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns MAR given eye landmarks\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    x1 = dist.euclidean(mouth[0], mouth[6])\n",
    "    y1 = dist.euclidean(mouth[1], mouth[11])\n",
    "    y2 = dist.euclidean(mouth[2], mouth[10])\n",
    "    y3 = dist.euclidean(mouth[3], mouth[9])\n",
    "    y4 = dist.euclidean(mouth[4], mouth[8])\n",
    "    y5 = dist.euclidean(mouth[5], mouth[7])\n",
    "    mar=(y1+y2+y3+y4+y5)/(2*x1)\n",
    "    return mar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db2ca297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return direction given the nose and anchor points.\n",
    "def direction (point, origin, w, h):\n",
    "    x = point [0]-origin [0]\n",
    "    y = point [1]-origin [1]\n",
    "    cv2.putText(frame, str(x)+\" \"+str(y)+ str(point)+ str(origin), (300, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, RED_COLOR, 2)\n",
    "    if abs(x)>abs(y) and abs(x)>w:\n",
    "        if x>0:\n",
    "            return \"right\"\n",
    "        else:\n",
    "            return \"left\"\n",
    "    elif abs(y)>abs(x) and abs(y)>h:\n",
    "            if y>0:\n",
    "                return \"down\"\n",
    "            else:\n",
    "                return \"up\"\n",
    "    else:\n",
    "        return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc6da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Grab the frame from the threaded video file stream, resize\n",
    "    # it, and convert it to grayscale\n",
    "    # channels)\n",
    "    _, frame = vid.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = imutils.resize(frame, width=cam_w, height=cam_h)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale frame\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "    # Loop over the face detections\n",
    "    if len(rects) > 0:\n",
    "        rect = rects[0]\n",
    "    else:\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        continue\n",
    "\n",
    "    # Determine the facial landmarks for the face region, then\n",
    "    # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "    # array\n",
    "    shape = predictor(gray, rect)\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "    # Extract the left and right eye coordinates, then use the\n",
    "    # coordinates to compute the eye aspect ratio for both eyes\n",
    "    mouth = shape[mStart:mEnd]\n",
    "    leftEye = shape[lStart:lEnd]\n",
    "    rightEye = shape[rStart:rEnd]\n",
    "    nose = shape[nStart:nEnd]\n",
    "\n",
    "    # Because I flipped the frame, left is right, right is left.\n",
    "    temp = leftEye\n",
    "    leftEye = rightEye\n",
    "    rightEye = temp\n",
    "\n",
    "    # Average the mouth aspect ratio together for both eyes\n",
    "    mar = mouth_aspect_ratio(mouth)\n",
    "    leftEAR = eye_aspect_ratio(leftEye)\n",
    "    rightEAR = eye_aspect_ratio(rightEye)\n",
    "    ear = (leftEAR + rightEAR) / 2.0\n",
    "    diff_ear = np.abs(leftEAR - rightEAR)\n",
    "\n",
    "    nose_point = (nose[3, 0], nose[3, 1])\n",
    "\n",
    "    # Compute the convex hull for the left and right eye, then\n",
    "    # visualize each of the eyes\n",
    "    mouthHull = cv2.convexHull(mouth)\n",
    "    leftEyeHull = cv2.convexHull(leftEye)\n",
    "    rightEyeHull = cv2.convexHull(rightEye)\n",
    "    cv2.drawContours(frame, [mouthHull], -1, YELLOW_COLOR, 1)\n",
    "    cv2.drawContours(frame, [leftEyeHull], -1, YELLOW_COLOR, 1)\n",
    "    cv2.drawContours(frame, [rightEyeHull], -1, YELLOW_COLOR, 1)\n",
    "\n",
    "    for (x, y) in np.concatenate((mouth, leftEye, rightEye), axis=0):\n",
    "        cv2.circle(frame, (x, y), 2, GREEN_COLOR, -1)\n",
    "        \n",
    "    # Check to see if the eye aspect ratio is below the blink\n",
    "    # threshold, and if so, increment the blink frame counter\n",
    "    if diff_ear > WINK_AR_DIFF_THRESH:\n",
    "\n",
    "        if leftEAR < rightEAR:\n",
    "            if leftEAR < EYE_AR_THRESH:\n",
    "                WINK_COUNTER += 1\n",
    "\n",
    "                if WINK_COUNTER > WINK_CONSECUTIVE_FRAMES:\n",
    "                    pyag.click(button='left')\n",
    "\n",
    "                    WINK_COUNTER = 0\n",
    "\n",
    "        elif leftEAR > rightEAR:\n",
    "            if rightEAR < EYE_AR_THRESH:\n",
    "                WINK_COUNTER += 1\n",
    "\n",
    "                if WINK_COUNTER > WINK_CONSECUTIVE_FRAMES:\n",
    "                    pyag.click(button='right')\n",
    "\n",
    "                    WINK_COUNTER = 0\n",
    "        else:\n",
    "            WINK_COUNTER = 0\n",
    "    else:\n",
    "        if ear <= EYE_AR_THRESH:\n",
    "            EYE_COUNTER += 1\n",
    "\n",
    "            if EYE_COUNTER > EYE_AR_CONSECUTIVE_FRAMES:\n",
    "                SCROLL_MODE = not SCROLL_MODE\n",
    "                # INPUT_MODE = not INPUT_MODE\n",
    "                EYE_COUNTER = 0\n",
    "\n",
    "                # nose point to draw a bounding box around it\n",
    "\n",
    "        else:\n",
    "            EYE_COUNTER = 0\n",
    "            WINK_COUNTER = 0\n",
    "\n",
    "    if mar > MOUTH_AR_THRESH:\n",
    "        MOUTH_COUNTER += 1\n",
    "\n",
    "        if MOUTH_COUNTER >= MOUTH_AR_CONSECUTIVE_FRAMES:\n",
    "            # if the alarm is not on, turn it on\n",
    "            INPUT_MODE = not INPUT_MODE\n",
    "            # SCROLL_MODE = not SCROLL_MODE\n",
    "            MOUTH_COUNTER = 0\n",
    "            ANCHOR_POINT = nose_point\n",
    "\n",
    "    else:\n",
    "        MOUTH_COUNTER = 0\n",
    "\n",
    "    if INPUT_MODE:\n",
    "        cv2.putText(frame, \"READING INPUT!\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, RED_COLOR, 2)\n",
    "        x, y = ANCHOR_POINT\n",
    "        nx, ny = nose_point\n",
    "        w, h = 60, 35\n",
    "        multiple = 1\n",
    "        cv2.rectangle(frame, (x - w, y - h), (x + w, y + h), GREEN_COLOR, 2)\n",
    "        cv2.line(frame, ANCHOR_POINT, nose_point, BLUE_COLOR, 2)\n",
    "\n",
    "        dir = direction(nose_point, ANCHOR_POINT, w, h)\n",
    "        cv2.putText(frame, dir.upper(), (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, RED_COLOR, 2)\n",
    "        drag = 18\n",
    "        if dir == 'right':\n",
    "            pyag.moveRel(drag, 0)\n",
    "        elif dir == 'left':\n",
    "            pyag.moveRel(-drag, 0)\n",
    "        elif dir == 'up':\n",
    "            if SCROLL_MODE:\n",
    "                pyag.scroll(40)\n",
    "            else:\n",
    "                pyag.moveRel(0, -drag)\n",
    "        elif dir == 'down':\n",
    "            if SCROLL_MODE:\n",
    "                pyag.scroll(-40)\n",
    "            else:\n",
    "                pyag.moveRel(0, drag)\n",
    "\n",
    "    if SCROLL_MODE:\n",
    "        cv2.putText(frame, 'SCROLL MODE IS ON!', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, RED_COLOR, 2)\n",
    "\n",
    "    # cv2.putText(frame, \"MAR: {:.2f}\".format(mar), (500, 30),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, YELLOW_COLOR, 2)\n",
    "    # cv2.putText(frame, \"Right EAR: {:.2f}\".format(rightEAR), (460, 80),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, YELLOW_COLOR, 2)\n",
    "    # cv2.putText(frame, \"Left EAR: {:.2f}\".format(leftEAR), (460, 130),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, YELLOW_COLOR, 2)\n",
    "    # cv2.putText(frame, \"Diff EAR: {:.2f}\".format(np.abs(leftEAR - rightEAR)), (460, 80),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # If the `Esc` key was pressed, break from the loop\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "# Do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cf722a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7352a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
